# prometheus/genesis_engine/core/implicit_relation_finder.py

from typing import List, Dict, Optional, Callable
from google import genai
import json
from prometheus.config.settings import settings
from prometheus.connectors.neo4j_connector import Neo4jConnector
from .cost_calculator import RelationCostCalculator
from prometheus.genesis_engine.models import ImplicitRelation

# (Kita bisa membuat model Pydantic untuk output JSON ini jika mau, tapi untuk sekarang dictionary sudah cukup)

PROMPT_TEMPLATE = """
You are an expert data architect. Your task is to analyze the semantic descriptions of two database tables and determine if a meaningful, implicit business relationship likely exists between them.

### CONTEXT
The descriptions below were generated by an AI analyzing the database schema, naming conventions, and data samples.

### Table A
- Name: {table_a_name}
- Description: {table_a_description}
- Stereotype: {table_a_stereotype}

### Table B
- Name: {table_b_name}
- Description: {table_b_description}
- Stereotype: {table_b_stereotype}

### ANALYSIS TASK
Based *only* on the context provided, answer the following questions and provide the output in a single, raw JSON object.
1.  `relationship_exists`: boolean. Is there a strong, logical business relationship between these two tables?
2.  `confidence_score`: float (0.0 to 1.0). How confident are you in your decision?
3.  `relationship_type`: string (if relationship_exists is true). Describe the relationship from A to B using a concise VERB_PHRASE (e.g., "HAS_SALE_ORDERS", "ASSIGNED_TO_USER"). Otherwise, null.
4.  `justification`: string. A brief, one-sentence explanation for your decision.

### JSON OUTPUT ONLY:
"""

class ImplicitRelationFinder:
    def __init__(self, neo4j_connector: Neo4jConnector, relation_creation_fn: Callable):
        self.connector = neo4j_connector
        self.create_relation_in_kg = relation_creation_fn

        # Support either direct Generative AI API via API key or Vertex AI via ADC
        if settings.use_vertex_ai:
            if not settings.gcp_project_id or not settings.gcp_location:
                raise ValueError("Vertex AI enabled but gcp_project_id or gcp_location is not set in settings.")
            self._client = genai.Client(
                vertexai=True,
                project=settings.gcp_project_id,
                location=settings.gcp_location,
            )
        else:
            if not settings.google_api_key:
                raise ValueError("Google API key not found in settings.")
            self._client = genai.Client(api_key=settings.google_api_key.get_secret_value())
        self.model = settings.relation_model_name
        self.cost_calculator = RelationCostCalculator()

    def find_and_create_relations(self, top_k: int = 5, min_similarity_score: float = 0.8, min_llm_confidence: float = 0.85):
        print("\n--- Starting Implicit Relation Discovery ---")
        
        # 1. Dapatkan semua node Tabel yang telah diperkaya
        source_nodes = self._get_enriched_tables()
        if not source_nodes:
            print("  - No enriched tables found to analyze. Skipping.")
            return

        print(f"  - Analyzing {len(source_nodes)} source tables to find implicit relations...")
        total_relations_found = 0

        for source_node in source_nodes:
            # 2. Untuk setiap node, cari tetangga terdekatnya menggunakan indeks vektor
            candidates = self._find_vector_candidates(source_node, top_k, min_similarity_score)
            
            for candidate_node, score in candidates:
                # 3. Verifikasi setiap kandidat dengan LLM
                verification_result, usage_data = self._verify_with_llm(source_node, candidate_node) # type: ignore
                
                if usage_data:
                    self.cost_calculator.track_call(
                        prompt_tokens=usage_data['prompt_tokens'],
                        completion_tokens=usage_data['completion_tokens']
                    ) # type: ignore
                
                if verification_result and \
                   verification_result.relationship_exists and \
                   verification_result.confidence_score >= min_llm_confidence:
                    
                    rel_type = verification_result.relationship_type
                    print(f"  ✅ Found implicit relation: ({source_node['name']}) -[:{rel_type}]-> ({candidate_node['name']})")
                    self.create_relation_in_kg(
                        source_node['name'],
                        candidate_node['name'],
                        verification_result # Teruskan seluruh objek Pydantic
                    )
                    total_relations_found += 1
        
        print(f"\n--- Implicit Relation Discovery Finished. Found {total_relations_found} new relationships. ---")
        pass

    def _get_enriched_tables(self) -> List[Dict]:
        query = "MATCH (t:Table) WHERE t.embedding IS NOT NULL RETURN t.name AS name, t.core_description AS description, t.stereotype AS stereotype, t.embedding AS embedding"
        with self.connector.get_session() as session:
            results = session.run(query).data()
            return [res for res in results if res.get('embedding')]

    def _find_vector_candidates(self, source_node: Dict, top_k: int, min_score: float) -> List[tuple]:
        query = """
        CALL db.index.vector.queryNodes('table_embeddings', $top_k, $source_vector)
        YIELD node, score
        // Filter kandidat: skor minimum, bukan node itu sendiri, dan belum ada relasi eksplisit
        WHERE score >= $min_score AND node.name <> $source_name
        AND NOT EXISTS { (n)-[:EXPLICIT_FK_TO|IMPLICIT_RELATION_TO]-(node) WHERE n.name = $source_name }
        RETURN node.name AS name, node.core_description AS description, node.stereotype AS stereotype, score
        """
        with self.connector.get_session() as session:
            results = session.run(query, 
                                  top_k=top_k + 1, # Ambil k+1 karena node itu sendiri akan muncul
                                  source_vector=source_node['embedding'], 
                                  min_score=min_score, 
                                  source_name=source_node['name']
                                 ).data()
            # `(res, res['score'])` tidak perlu, karena `res` sudah berisi semua data
            return [(res, res['score']) for res in results]
        
    def _verify_with_llm(self, table_a: Dict, table_b: Dict) -> tuple[Optional[ImplicitRelation], Optional[Dict]]:
        prompt = PROMPT_TEMPLATE.format(
            table_a_name=table_a.get('name'),
            table_a_description=table_a.get('description'),
            table_a_stereotype=table_a.get('stereotype'),
            table_b_name=table_b.get('name'),
            table_b_description=table_b.get('description'),
            table_b_stereotype=table_b.get('stereotype'),
        )
        try:
            # Normalize model id when using Vertex AI
            model_id = self.model
            if settings.use_vertex_ai and isinstance(model_id, str) and model_id.startswith("models/"):
                model_id = model_id.split("/", 1)[1]
            completion = self._client.models.generate_content(
                model=model_id,
                contents=prompt,
                config={
                    "response_mime_type": "application/json",
                    "temperature": 0.1,
                },
            )
            response_content = getattr(completion, "output_text", None) or getattr(completion, "text", None)
            if not response_content:
                print(f"⚠️ LLM returned an empty response for relation check between {table_a['name']} and {table_b['name']}.")
                return None, None

            parsed_json = json.loads(response_content) # type: ignore

            validated_relation = ImplicitRelation(**parsed_json)
            
            um = getattr(completion, "usage_metadata", None)
            usage_data = {
                "prompt_tokens": getattr(um, "prompt_token_count", 0) if um else 0,
                "completion_tokens": getattr(um, "candidates_token_count", 0) if um else 0
            }

            # Kembalikan objek Pydantic yang sudah divalidasi
            return validated_relation, usage_data

        except Exception as e:
            print(f"⚠️ LLM verification failed between {table_a['name']} and {table_b['name']}: {e}")
            return None, None